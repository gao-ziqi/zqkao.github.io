
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>FAB: A Robust Facial Landmark Detection Framework for Motion-Blurred Videos</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="We introduced an important but omitted issue, the facial landmark detection in motion-blurred videos. We believe further research on this field is of great significance. We proposed a novel framework, in which the three components work as an organic whole. The face boundary yielded by the structure predictor assists the deblurring module to relieve the motion blur. And the deblurred face leads to more accurate facial landmarks. There is still a lot of room for improvement for the extreme motion blur of the proposed RWMB dataset. We hope to see further development of this work in the future.">
<meta name="keywords" content="FAB; RWMB; Real-World Motion Blur; facial landmark detection in motion-blurred videos; face alignment; motion blur; deep learning; Convolutional network; computer vision;">
<link rel="author" href="http://keqiangsun.github.io/">

<!-- Fonts and stuff -->
<link href="css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="iconize.css">
<script async="" src="prettify.js"></script>



</head>


<body>
  <div id="content">
    <div id="content-inner">
      
      <div class="section head">
	<h1><font size="5">FAB: A Robust Facial Landmark Detection Framework for Motion-Blurred Videos</font></h1>

	<div class="authors">
			<a href="http://keqiangsun.github.io/">Keqiang Sun</a><sup>1,2</sup>&nbsp;&nbsp;
			<a href="http://wuwy.github.io/">Wayne Wu</a><sup>2</sup>&nbsp;&nbsp;
			<a href="">Tinghao Liu</a><sup>3</sup>&nbsp;&nbsp;
			<a href="http://shuoyang1213.me/">Shuo Yang</a><sup>4</sup>&nbsp;&nbsp;
			<a href="">Quan Wang</a><sup>3</sup>&nbsp;&nbsp;
			<a href="">Qiang Zhou</a><sup>2</sup>&nbsp;&nbsp;
			<a href="">Chen Qian</a><sup>1</sup>&nbsp;&nbsp;
			<a href="">Zuochang Ye</a><sup>3</sup>
		</div>

		<div class="affiliations">
				<sup>1</sup><a href="http://www.ime.tsinghua.edu.cn/publish/ime/5886/index.html">Institute of Microelectronics, Tsinghua University<br></a>
			<sup>2</sup><a href="http://www.sist.tsinghua.edu.cn/docinfo_eng/index.jsp">Tsinghua National Laboratory for Information Science and Technology (TNList),<br>Department of Computer Science and Technology, Tsinghua University<br></a>
			<sup>3</sup><a href="https://www.sensetime.com/?lang=en-us">SenseTime Research<br></a>
			<sup>4</sup><a href="https://aws.amazon.com/cn/rekognition/">Amazon Rekognition</a>
		</div>
		<ul id="tabs">
			<li><a href="https://keqiangsun.github.io/projects/FAB/FAB.html" name="#tab1">FAB</a></li>
			<li><a href="https://keqiangsun.github.io/projects/FAB/RWMB.html" name="#tab2">RWMB</a></li>  
		</ul>
	</div>


<!-- 	<div class="venue">International Conference on Computer Vision (<a href="http://pamitc.org/iccv15/" target="_blank">ICCV</a>) 2015, Santiago, Chile</div> -->

      
	<center><img src="./support/WFLF_index.png" border="0" width="92.5%"></center>
	
	<div class="section abstract">
	<h2>Abstract</h2>
	<p>
	Wider Facial Landmarks in-the-wild (WFLW) contains 10000 faces (7500 for training and 2500 for testing) with 98 fully manual annotated landmarks. Apart from landmark annotation, out new dataset includes rich attribute annotations, i.e., occlusion, pose, make-up, illumination, blur and expression for comprehensive analysis of existing algorithms. Compare to previous dataset, faces in the proposed dataset introduce large variations in expression, pose and occlusion. We can simply evaluate the robustness of pose, occlusion, and expression on proposed dataset instead of switching between multiple evaluation protocols in different datasets.
	</p>
	</div>

	<div class="section Download">
	<h2 id="Download (Academic usage only)">Download</h2>  	
	<p>
	</p><ul>
	<li>WFLW Training and Testing Images <a href="https://drive.google.com/open?id=1hzBd48JIdWTJSsATBEB_eFVvPL1bx6UC">[Google Drive]</a>  <a href="https://pan.baidu.com/s/1paoOpusuyafHY154lqXYrA">[Baidu Drive]</a></li>
	<li><a href="./support/WFLW_annotations.tar.gz">WFLW Face Annotations</a></li>
	</ul>	
	<p></p>
	</div>

	<div class="section Landmark Definition">
	<h2 id="Landmark Definition">Landmark Definition</h2>
	<p>
	<center><img src="./support/WFLW_annotation.png" border="0" width="80%"></center>
	</p>
	</div>


	<div class="section Multi-View Illustration">
	<h2 id="Multi-View Illustration">Multi-View Illustration</h2>
	<p>
	<center><img src="./support/WFLW_multiview.png" border="0" width="80%"></center>
	</p>
	</div>

	<div class="section Results">
	<h2 id="Results">Results</h2>
	<p>
	<center><img src="./support/WFLW_results.png" border="0" width="85%"></center>
	</p>
	</div>


<br>
 <div class="section list">
	<h2>Citation</h2>
	
	<div class="section bibtex">
	  <pre>
@inproceedings{keqiang2019fab,
author = {Sun, Keqiang and Wu, Wayne and Liu, Tinghao and Yang, Shuo and Wang, Quan and Zhou, Qiang and and Ye, Zuochang and Qian, Chen},
title = {FAB: A Robust Facial Landmark Detection Framework for Motion-Blurred Videos},
booktitle = {ICCV},
month = October,
year = {2019}
}
	</pre>
	  </div>
      </div>

     <div class="section contact">
	<h2>Contact</h2>
	Keqiang Sun<br><a href="mailto:sdk17@mails.tsinghua.edu.cn">sdk17@mails.tsinghua.edu.cn</a>
      </div>
    </div>
  </div>

</body></html>
